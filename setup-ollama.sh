#!/bin/bash

echo "ğŸš€ Setting up Ollama for local AI SMS parsing..."

# Check if Ollama is already installed
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed"
else
    echo "ğŸ“¥ Installing Ollama..."
    
    # Install Ollama (macOS)
    if [[ "$OSTYPE" == "darwin"* ]]; then
        curl -fsSL https://ollama.ai/install.sh | sh
    else
        echo "âŒ Please install Ollama manually from https://ollama.ai/install"
        exit 1
    fi
fi

# Start Ollama service
echo "ğŸ”„ Starting Ollama service..."
ollama serve &

# Wait for service to start
sleep 5

# Download the model
echo "ğŸ“¦ Downloading Llama 3.1 8B model (this may take a few minutes)..."
ollama pull llama3.1:8b

echo "âœ… Setup complete!"
echo ""
echo "ğŸ¯ Your SMS parser now supports:"
echo "   â€¢ Fast regex parsing for common formats"
echo "   â€¢ AI fallback for complex/natural language"
echo "   â€¢ Local processing (no API costs)"
echo "   â€¢ Caching for performance"
echo ""
echo "ğŸ“± Try texting:"
echo "   RESERVATION 2 guests on 6/27/25 at 6:30pm"
echo "   RESERVATION for 4 people tomorrow at 8pm"
echo "   RESERVATION party of 6 next Friday 7:30pm"
echo ""
echo "ğŸ”§ To use a faster model, run: ollama pull mistral:7b"
echo "   Then update the model name in the code to 'mistral:7b'" 